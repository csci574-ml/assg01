{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 01: Python Functions and Numpy Vectorization\n",
    "---\n",
    "\n",
    "**Due Date:** Friday 09/05/2025 (by midnight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Please fill these in before submitting, just in case I accidentally mix up file names while grading**:\n",
    "\n",
    "Name: Jane Hacker\n",
    "\n",
    "CWID-5: (Last 5 digits of cwid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction \n",
    "\n",
    "In this assignment you will get some tasks to help familarize you with programming Python \n",
    "and creating vectorized NumPy functions.  \n",
    "\n",
    "Even if you've used Python before, these exercises will help familarize you with functions you will\n",
    "be using in this course, and a few basic concepts.\n",
    "\n",
    "**Instructions**:\n",
    "\n",
    "- You need to use the class development environment and make sure that you are pushing your assignments to your\n",
    "  GitHub classroom and they are successfully passing the autograder.\n",
    "- Avoid using for-loops and while loops, unless you are explicitly told to do so.\n",
    "- Do not modify the `### TESTED FUNCTION [function name]` cells.  These cells call unit tests on the functions\n",
    "  you are asked to write for these assignments.\n",
    "- All functions you need to write should be placed into the `src/assginment_tasks.py` file.  Functions that are\n",
    "  tested and graded are imported from there into this notebook.\n",
    "  - For this assignment you have been given a stub function and documentation for the function.  In the future you will\n",
    "    need to add in the function from scratch yourself for each task.\n",
    "- After coding your function, run the `### TESTED FUNCTION` cell to determine if it is passing the assignment\n",
    "  unit tests and that your result is correct.\n",
    "\n",
    "**After this assignmeent you will**:\n",
    "- Be able to use iPython Notebooks\n",
    "- Be familiar with using our GitHub classroom workflow and the GitHub autograder for your assignments.\n",
    "- Understand the concept of \"broadcasting\"\n",
    "- Understand and be able to vectorize code.\n",
    "- Have practiced writing Python and vectorized NumPy functions and operations.\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following ipython magic will reload changed file/modules.\n",
    "# So when editing function in source code modules, you should\n",
    "# be able to just rerun the cell, not restart the whole kernel.\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assignment wide imports go here, usually all of your imports for noteboosk should\n",
    "# be put up at the top here, if they were not given to you at the start of the assignment\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import functions/moduls from this project.  We manually set the\n",
    "# PYTHONPATH to append the location to search for this assignments\n",
    "# functions to just ensure the imports are found\n",
    "#import sys\n",
    "#sys.path.append(\"../src\")\n",
    "\n",
    "# assignment function imports for doctests and github autograding\n",
    "# these are required for assignment autograding\n",
    "from assg_utils import run_unittests, run_doctests\n",
    "from assg_tasks import basic_sigmoid\n",
    "from assg_tasks import sigmoid\n",
    "from assg_tasks import sigmoid_grad\n",
    "from assg_tasks import standard_scalar\n",
    "from assg_tasks import softmax\n",
    "from assg_tasks import one_hot\n",
    "from assg_tasks import rmse\n",
    "from assg_tasks import mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Building basic functions with `NumPy`\n",
    "\n",
    "`NumPy` is the main package for scientific computing in Python. It is maintained by a large community (www.numpy.org). In this exercise you will learn several key numpy functions such as np.exp, np.log, and np.reshape. You will need to know how to use these functions for future assignments.\n",
    "\n",
    "### Task 1.1: sigmoid function, np.exp()\n",
    "\n",
    "Before using np.exp(), you will use math.exp() to implement the sigmoid function. You will then see why np.exp() is preferable to math.exp().\n",
    "\n",
    "**Task**: Implement the function named `basic_sigmoid()` that returns the sigmoid of a real number x. Use math.exp(x) for the exponential function.\n",
    "\n",
    "**Reminder**:\n",
    "$\\text{sigmoid}(x) = \\frac{1}{1+e^{-x}}$ is sometimes also known as the logistic function. It is a non-linear function used not only in Machine Learning (Logistic Regression), but also in Deep Learning.\n",
    "\n",
    "<img src=\"../figures/Sigmoid.png\" style=\"width:500px;height:228px;\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_input_0 (test_assg_tasks.test_basic_sigmoid.test_input_0)\n",
      "test_input_0 ... FAIL\n",
      "test_input_3 (test_assg_tasks.test_basic_sigmoid.test_input_3)\n",
      "test_input_3 ... FAIL\n",
      "test_input_neg5 (test_assg_tasks.test_basic_sigmoid.test_input_neg5)\n",
      "test_input_neg5 ... FAIL\n",
      "test_using_math_library (test_assg_tasks.test_basic_sigmoid.test_using_math_library)\n",
      "test_using_math_library ... FAIL\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_input_0 (test_assg_tasks.test_basic_sigmoid.test_input_0)\n",
      "test_input_0\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/defer.py\", line 216, in maybeDeferred\n",
      "    result = f(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 227, in runWithWarningsSuppressed\n",
      "    raise exc_info[1].with_traceback(exc_info[2])\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 223, in runWithWarningsSuppressed\n",
      "    result = f(*a, **kw)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/workspaces/assg02/src/test_assg_tasks.py\", line 28, in test_input_0\n",
      "    self.assertAlmostEqual(s, 0.5)\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/trial/_synctest.py\", line 565, in assertAlmostEqual\n",
      "    raise self.failureException(\n",
      "twisted.trial.unittest.FailTest: 0.0 != 0.5 within 7 places\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_input_3 (test_assg_tasks.test_basic_sigmoid.test_input_3)\n",
      "test_input_3\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/defer.py\", line 216, in maybeDeferred\n",
      "    result = f(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 227, in runWithWarningsSuppressed\n",
      "    raise exc_info[1].with_traceback(exc_info[2])\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 223, in runWithWarningsSuppressed\n",
      "    result = f(*a, **kw)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/workspaces/assg02/src/test_assg_tasks.py\", line 24, in test_input_3\n",
      "    self.assertAlmostEqual(s, 0.9525741268224334)\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/trial/_synctest.py\", line 565, in assertAlmostEqual\n",
      "    raise self.failureException(\n",
      "twisted.trial.unittest.FailTest: 0.0 != 0.9525741268224334 within 7 places\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_input_neg5 (test_assg_tasks.test_basic_sigmoid.test_input_neg5)\n",
      "test_input_neg5\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/defer.py\", line 216, in maybeDeferred\n",
      "    result = f(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 227, in runWithWarningsSuppressed\n",
      "    raise exc_info[1].with_traceback(exc_info[2])\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 223, in runWithWarningsSuppressed\n",
      "    result = f(*a, **kw)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/workspaces/assg02/src/test_assg_tasks.py\", line 32, in test_input_neg5\n",
      "    self.assertAlmostEqual(s, 0.0066928509242848554)\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/trial/_synctest.py\", line 565, in assertAlmostEqual\n",
      "    raise self.failureException(\n",
      "twisted.trial.unittest.FailTest: 0.0 != 0.0066928509242848554 within 7 places\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_using_math_library (test_assg_tasks.test_basic_sigmoid.test_using_math_library)\n",
      "test_using_math_library\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/defer.py\", line 216, in maybeDeferred\n",
      "    result = f(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 227, in runWithWarningsSuppressed\n",
      "    raise exc_info[1].with_traceback(exc_info[2])\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 223, in runWithWarningsSuppressed\n",
      "    result = f(*a, **kw)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/workspaces/assg02/src/test_assg_tasks.py\", line 38, in test_using_math_library\n",
      "    with self.assertRaises(TypeError):\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/trial/_synctest.py\", line 333, in __exit__\n",
      "    self._testCase.fail(\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/trial/_synctest.py\", line 381, in fail\n",
      "    raise self.failureException(msg)\n",
      "twisted.trial.unittest.FailTest: TypeError not raised (None returned)\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.213s\n",
      "\n",
      "FAILED (failures=4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "basic_sigmoid(3) returned: 0.000000\n"
     ]
    }
   ],
   "source": [
    "#### TESTED FUNCTION basic_sigmoid()\n",
    "run_unittests(['test_basic_sigmoid'])\n",
    "\n",
    "res = basic_sigmoid(3)\n",
    "print('basic_sigmoid(3) returned: %f' % res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actually, we rarely use the \"math\" library in machine learning because the inputs of the functions are real numbers. In machine learning we mostly use matrices and vectors. This is why numpy is more useful.\n",
    "\n",
    "For example, if you try and calculate the sigmoid for an array of values, you get an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One reason why we use \"numpy\" instead of \"math\" in Deep Learning, \"numpy\" functions\n",
    "# are vectorized by default\n",
    "x = np.array([-5, 0, 3])\n",
    "try:\n",
    "    basic_sigmoid(x)\n",
    "except TypeError:\n",
    "    print('basic_sigmoid() threw a TypeError because it expects a single scalar value as input')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In fact, if $x = (x_1, x_2, ..., x_n)$ is a row vector then $np.exp(x)$ will apply the exponential function to every element of x. The output will thus be: $\\text{np.exp}(x) = (e^{x_1}, e^{x_2}, ..., e^{x_n})$ (e.g.\n",
    "the numpy version of the `exp()` function is vectorized)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.73794700e-03 1.00000000e+00 2.00855369e+01]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# example of np.exp\n",
    "x = np.array([-5, 0, 3])\n",
    "print(np.exp(x)) # result is (exp(1), exp(2), exp(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore, if x is a numpy vector, then a Python operation such as $s = x + 3$ or $s = \\frac{1}{x}$ will output s as a vector of the same size as x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 5 6]\n"
     ]
    }
   ],
   "source": [
    "# example of vector operation\n",
    "x = np.array([1, 2, 3])\n",
    "print (x + 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any time you need more info on a numpy function, we encourage you to look at [the official documentation](https://docs.scipy.org/doc/numpy-1.10.1/reference/generated/numpy.exp.html). \n",
    "\n",
    "You can also create a new cell in the notebook and write `np.exp?` (for example) to get quick access to the documentation.\n",
    "\n",
    "**Task**: Implement the sigmoid function using numpy so that your function is vectorized. \n",
    "\n",
    "**Instructions**: x could now be either a real number, a vector, or a matrix. The data structures we use in numpy to represent these shapes (vectors, matrices...) are called numpy arrays. You don't need to know more for now.\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{For } x \\in \\mathbb{R}^n \\text{,     } \\text{sigmoid}(x) = \\text{sigmoid}\n",
    "\\begin{pmatrix}\n",
    "    x_1  \\\\\n",
    "    x_2  \\\\\n",
    "    ...  \\\\\n",
    "    x_n  \\\\\n",
    "\\end{pmatrix} = \n",
    "\\begin{pmatrix}\n",
    "    \\frac{1}{1+e^{-x_1}}  \\\\\n",
    "    \\frac{1}{1+e^{-x_2}}  \\\\\n",
    "    ...  \\\\\n",
    "    \\frac{1}{1+e^{-x_n}}  \\\\\n",
    "\\end{pmatrix}\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_input_list (test_assg_tasks.test_sigmoid.test_input_list)\n",
      "test_input_list ... FAIL\n",
      "test_input_matrix (test_assg_tasks.test_sigmoid.test_input_matrix)\n",
      "test_input_matrix ... FAIL\n",
      "test_input_scalar (test_assg_tasks.test_sigmoid.test_input_scalar)\n",
      "test_input_scalar ... ERROR\n",
      "test_input_vector (test_assg_tasks.test_sigmoid.test_input_vector)\n",
      "test_input_vector ... FAIL\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_input_scalar (test_assg_tasks.test_sigmoid.test_input_scalar)\n",
      "test_input_scalar\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/defer.py\", line 216, in maybeDeferred\n",
      "    result = f(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 227, in runWithWarningsSuppressed\n",
      "    raise exc_info[1].with_traceback(exc_info[2])\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 223, in runWithWarningsSuppressed\n",
      "    result = f(*a, **kw)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/workspaces/assg02/src/test_assg_tasks.py\", line 48, in test_input_scalar\n",
      "    self.assertAlmostEqual(s, 0.9525741268224334)\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/trial/_synctest.py\", line 564, in assertAlmostEqual\n",
      "    if round(second - first, places) != 0:\n",
      "       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: type numpy.ndarray doesn't define __round__ method\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_input_list (test_assg_tasks.test_sigmoid.test_input_list)\n",
      "test_input_list\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/defer.py\", line 216, in maybeDeferred\n",
      "    result = f(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 227, in runWithWarningsSuppressed\n",
      "    raise exc_info[1].with_traceback(exc_info[2])\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 223, in runWithWarningsSuppressed\n",
      "    result = f(*a, **kw)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/workspaces/assg02/src/test_assg_tasks.py\", line 78, in test_input_list\n",
      "    with self.assertRaises(TypeError):\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/trial/_synctest.py\", line 333, in __exit__\n",
      "    self._testCase.fail(\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/trial/_synctest.py\", line 381, in fail\n",
      "    raise self.failureException(msg)\n",
      "twisted.trial.unittest.FailTest: TypeError not raised (None returned)\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_input_matrix (test_assg_tasks.test_sigmoid.test_input_matrix)\n",
      "test_input_matrix\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/defer.py\", line 216, in maybeDeferred\n",
      "    result = f(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 227, in runWithWarningsSuppressed\n",
      "    raise exc_info[1].with_traceback(exc_info[2])\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 223, in runWithWarningsSuppressed\n",
      "    result = f(*a, **kw)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/workspaces/assg02/src/test_assg_tasks.py\", line 73, in test_input_matrix\n",
      "    self.assertTrue(np.allclose(s, expected_s))\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/trial/_synctest.py\", line 402, in assertTrue\n",
      "    super().assertTrue(condition, msg)\n",
      "twisted.trial.unittest.FailTest: False is not true\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_input_vector (test_assg_tasks.test_sigmoid.test_input_vector)\n",
      "test_input_vector\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/defer.py\", line 216, in maybeDeferred\n",
      "    result = f(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 227, in runWithWarningsSuppressed\n",
      "    raise exc_info[1].with_traceback(exc_info[2])\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 223, in runWithWarningsSuppressed\n",
      "    result = f(*a, **kw)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/workspaces/assg02/src/test_assg_tasks.py\", line 54, in test_input_vector\n",
      "    self.assertTrue(np.allclose(s, np.array([0.00669285, 0.5, 0.95257413])))\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/trial/_synctest.py\", line 402, in assertTrue\n",
      "    super().assertTrue(condition, msg)\n",
      "twisted.trial.unittest.FailTest: False is not true\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.009s\n",
      "\n",
      "FAILED (failures=3, errors=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigmoid(s) returned:\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "#### TESTED FUNCTION sigmoid()\n",
    "run_unittests(['test_sigmoid'])\n",
    "\n",
    "x = np.array([-5, 0, 3])\n",
    "s = sigmoid(x)\n",
    "print('sigmoid(s) returned:')\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your vectorized implementation of the `sigmoid()` function is working,\n",
    "the following cell should recreate the plot of the sigmod function\n",
    "you were shown above.  \n",
    "\n",
    "Uncomment the call to your `sigmoid()` function and to plot it to see if you are getting the expected results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1342/2743136378.py:7: UserWarning: No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "  plt.legend();\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.linspace(-8, 8, 100)\n",
    "#t = sigmoid(x)\n",
    "#plt.plot(x, t, 'r-', label=r'$sigmoid(t)=\\frac{1}{1 + e^{-t}}$')\n",
    "plt.grid()\n",
    "plt.xlabel('t')\n",
    "plt.ylabel(r'$sigmoid(t)$')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have completed two functions, `basic_sigmoid()` and `sigmoid()` at this point for the\n",
    "first part of Task 1.  You should go ahead and create a commit and push it to your\n",
    "GitHub Classroom repository now if your functions are working, and check that it passes the\n",
    "assignment Autograder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.2: sigmoid gradient\n",
    "\n",
    "As you will see in our class, you will need to compute gradients to optimize loss functions using backpropagation. Let's code your first gradient function.\n",
    "\n",
    "**Task**: Implement the function sigmoid_grad() to compute the gradient of the sigmoid function with respect to its input x. The formula is: \n",
    "\n",
    "\\begin{equation}\n",
    "\\text{sigmoid\\_grad}(x) = \\text{sigmoid}(x) (1 - \\text{sigmoid}(x))\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "You often code this function in two steps:\n",
    "1. Set s to be the sigmoid of x. You are required to reuse your `sigmoid(x)` function from the\n",
    "   previous task to do this, e.g. don't repeat yourself.\n",
    "3. Compute $\\text{sigmoid\\_grad}(x) = s(1-s)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_input_list (test_assg_tasks.test_sigmoid_grad.test_input_list)\n",
      "test_input_list ... FAIL\n",
      "test_input_matrix (test_assg_tasks.test_sigmoid_grad.test_input_matrix)\n",
      "test_input_matrix ... FAIL\n",
      "test_input_scalar (test_assg_tasks.test_sigmoid_grad.test_input_scalar)\n",
      "test_input_scalar ... ERROR\n",
      "test_input_vector (test_assg_tasks.test_sigmoid_grad.test_input_vector)\n",
      "test_input_vector ... FAIL\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_input_scalar (test_assg_tasks.test_sigmoid_grad.test_input_scalar)\n",
      "test_input_scalar\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/defer.py\", line 216, in maybeDeferred\n",
      "    result = f(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 227, in runWithWarningsSuppressed\n",
      "    raise exc_info[1].with_traceback(exc_info[2])\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 223, in runWithWarningsSuppressed\n",
      "    result = f(*a, **kw)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/workspaces/assg02/src/test_assg_tasks.py\", line 89, in test_input_scalar\n",
      "    self.assertAlmostEqual(s, 0.045176659730912)\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/trial/_synctest.py\", line 564, in assertAlmostEqual\n",
      "    if round(second - first, places) != 0:\n",
      "       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: type numpy.ndarray doesn't define __round__ method\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_input_list (test_assg_tasks.test_sigmoid_grad.test_input_list)\n",
      "test_input_list\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/defer.py\", line 216, in maybeDeferred\n",
      "    result = f(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 227, in runWithWarningsSuppressed\n",
      "    raise exc_info[1].with_traceback(exc_info[2])\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 223, in runWithWarningsSuppressed\n",
      "    result = f(*a, **kw)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/workspaces/assg02/src/test_assg_tasks.py\", line 119, in test_input_list\n",
      "    with self.assertRaises(TypeError):\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/trial/_synctest.py\", line 333, in __exit__\n",
      "    self._testCase.fail(\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/trial/_synctest.py\", line 381, in fail\n",
      "    raise self.failureException(msg)\n",
      "twisted.trial.unittest.FailTest: TypeError not raised (None returned)\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_input_matrix (test_assg_tasks.test_sigmoid_grad.test_input_matrix)\n",
      "test_input_matrix\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/defer.py\", line 216, in maybeDeferred\n",
      "    result = f(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 227, in runWithWarningsSuppressed\n",
      "    raise exc_info[1].with_traceback(exc_info[2])\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 223, in runWithWarningsSuppressed\n",
      "    result = f(*a, **kw)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/workspaces/assg02/src/test_assg_tasks.py\", line 114, in test_input_matrix\n",
      "    self.assertTrue(np.allclose(s, expected_s))\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/trial/_synctest.py\", line 402, in assertTrue\n",
      "    super().assertTrue(condition, msg)\n",
      "twisted.trial.unittest.FailTest: False is not true\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_input_vector (test_assg_tasks.test_sigmoid_grad.test_input_vector)\n",
      "test_input_vector\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/defer.py\", line 216, in maybeDeferred\n",
      "    result = f(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 227, in runWithWarningsSuppressed\n",
      "    raise exc_info[1].with_traceback(exc_info[2])\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 223, in runWithWarningsSuppressed\n",
      "    result = f(*a, **kw)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/workspaces/assg02/src/test_assg_tasks.py\", line 95, in test_input_vector\n",
      "    self.assertTrue(np.allclose(s, np.array([0.00664806, 0.25, 0.04517666])))\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/trial/_synctest.py\", line 402, in assertTrue\n",
      "    super().assertTrue(condition, msg)\n",
      "twisted.trial.unittest.FailTest: False is not true\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.008s\n",
      "\n",
      "FAILED (failures=3, errors=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigmoid_grad(s) returned:\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "#### TESTED FUNCTION sigmoid_grad()\n",
    "run_unittests(['test_sigmoid_grad'])\n",
    "\n",
    "x = np.array([-5, 0, 3])\n",
    "ds = sigmoid_grad(x)\n",
    "print('sigmoid_grad(s) returned:')\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once your `sigmod_grad()` function is passing your tests, you should create and push \n",
    "a commit of your Task 2.2 work to your GitHub classroom repository, and ensure that it is\n",
    "passing tests in the autograder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.3: Feature Scaling of Sample Data\n",
    "\n",
    "Another common task we need to do for Machine Learning is data normalization, where we scale numerical features of our data to have similar\n",
    "ranges.  We will discuss in class two common methods of normalizing data, min-max scaling and standard scaling.  Normalizing data using standard\n",
    "scaling is probably the most common technique, and has some advantages over min-max scaling.  \n",
    "\n",
    "In ML, when we have a matrix of data, each row represents a separate sample of the data, and the columns are the measured features for the\n",
    "collected data samples.\n",
    "\n",
    "![Terminology, data has n samples as rows and m column features](../figures/data-samples-features.png)\n",
    "\n",
    "In this example of the Iris dataset (that we will be using in this class), there are 150 samples, so `n = 150` rows are in the table.  There are `m = 4` separate\n",
    "measured features for each flower sample (petal length, petal width, sepal length and sepal width).  The fifth column has a target label that is not a numerical feature and\n",
    "is used for supervised training.\n",
    "\n",
    "Typically the numerical input features will be represented as a numpy array, in the previous example the array would have a shape of `(150, 4)`, and would be represented like\n",
    "the following:\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{bmatrix}\n",
    "    x_1^{(1)}  && x_2^{(1)} && x_3^{(1)}  && x_4^{(1)}  \\\\\n",
    "    x_1^{(2)}  && x_2^{(2)} && x_3^{(2)}  && x_4^{(2)}  \\\\\n",
    "    \\vdots && \\vdots && \\vdots && \\vdots \\\\\n",
    "    x_1^{(150)}  && x_2^{(150)} && x_3^{(150)}  && x_4^{(150)}  \\\\\n",
    "\\end{bmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "In order to perform standard feature scaling, we determine the average of each feature (column) of the data, and subtact each value in a column by the average.  This has\n",
    "the effect of \"centering\" the data so that the data now has a mean value of 0.  We also divide each column by the standard deviation of the column, which has the effect\n",
    "of normalizing the feature columns to all have a unit standard deviation (a standard deviation of 1).\n",
    "\n",
    "You will often see a greek `mu` $\\mu$ as representing the sample mean of a feature, and a greek `sigma` $\\sigma$ to represent the sample standard deviation.  So for example, \n",
    "we can represent the standard scaling operation for the $j^{th}$ feature as:\n",
    "\n",
    "\\begin{equation}\n",
    "x_j^` = \\frac{x_j - \\mu_j}{\\sigma_j}\n",
    "\\end{equation}\n",
    "\n",
    "Here $x_j$ is a vector (a column of our data matrix) consisting of the $j^{th}$ feature vales of all training examples, and $\\mu_j$ and $\\sigma_j$ are the sample mean and standard deviation\n",
    "of this feature.\n",
    "\n",
    "**Task**: Implement a function named `standard_scalar()` to perform this operation.  This function expects a matrix `x` of data of shape `(n, m)` with `n` rows of samples and `m` numerical column\n",
    "features.  You are required to implement this function using vectorized NumPy operations.  You should calculate the `mean()` and `std()`  of each column/feature of `x` and perform the\n",
    "centering and deviation normalization described.  The function should return a new copy of `x` that has been correctly normalized using standard feature scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_matrix (test_assg_tasks.test_standard_scalar.test_matrix)\n",
      "test_matrix ... FAIL\n",
      "test_random_matrix (test_assg_tasks.test_standard_scalar.test_random_matrix)\n",
      "test_random_matrix ... FAIL\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_matrix (test_assg_tasks.test_standard_scalar.test_matrix)\n",
      "test_matrix\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/defer.py\", line 216, in maybeDeferred\n",
      "    result = f(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 227, in runWithWarningsSuppressed\n",
      "    raise exc_info[1].with_traceback(exc_info[2])\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 223, in runWithWarningsSuppressed\n",
      "    result = f(*a, **kw)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/workspaces/assg02/src/test_assg_tasks.py\", line 140, in test_matrix\n",
      "    self.assertTrue(np.allclose(x_scaled, expected_x_scaled))\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/trial/_synctest.py\", line 402, in assertTrue\n",
      "    super().assertTrue(condition, msg)\n",
      "twisted.trial.unittest.FailTest: False is not true\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_random_matrix (test_assg_tasks.test_standard_scalar.test_random_matrix)\n",
      "test_random_matrix\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/defer.py\", line 216, in maybeDeferred\n",
      "    result = f(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 227, in runWithWarningsSuppressed\n",
      "    raise exc_info[1].with_traceback(exc_info[2])\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 223, in runWithWarningsSuppressed\n",
      "    result = f(*a, **kw)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/workspaces/assg02/src/test_assg_tasks.py\", line 199, in test_random_matrix\n",
      "    self.assertTrue(np.allclose(x_scaled, expected_x_scaled))\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/trial/_synctest.py\", line 402, in assertTrue\n",
      "    super().assertTrue(condition, msg)\n",
      "twisted.trial.unittest.FailTest: False is not true\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 0.006s\n",
      "\n",
      "FAILED (failures=2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "standard_scalar returned:\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "the mean and std of the scaled data:\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "#### TESTED FUNCTION normalize_rows()\n",
    "run_unittests(['test_standard_scalar'])\n",
    "\n",
    "x = np.array(\n",
    "    [[0,   3,   5,  3],\n",
    "     [1,   6,   4,  8],\n",
    "     [-1, 10, -20, 22]]\n",
    ")\n",
    "\n",
    "x_scaled, x_mu, x_sigma = standard_scalar(x)\n",
    "print('standard_scalar returned:')\n",
    "print(x_scaled)\n",
    "print(x_mu)\n",
    "print(x_sigma)\n",
    "print('the mean and std of the scaled data:')\n",
    "print(x_scaled.mean(axis=0))\n",
    "print(x_scaled.std(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Results**: Given the example input array `x` with 3 samples and 4 numerical features, you should get the following results from the output in the \n",
    "previous cell\n",
    "\n",
    "```\n",
    "standard_scalar returned:\n",
    "[[ 0.         -1.16247639  0.74993067 -0.99483201]\n",
    " [ 1.22474487 -0.11624764  0.66340021 -0.373062  ]\n",
    " [-1.22474487  1.27872403 -1.41333087  1.36789401]]\n",
    "[ 0.          6.33333333 -3.66666667 11.        ]\n",
    "[ 0.81649658  2.86744176 11.55662388  8.04155872]\n",
    "\n",
    "the mean and std of the scaled data:\n",
    "[0.00000000e+00 1.48029737e-16 0.00000000e+00 0.00000000e+00]\n",
    "[1. 1. 1. 1.]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 1.3 is complete, make a commit and push your work and make sure all tests for the\n",
    "tasks you have completed are passing in the autograder at this point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.4: Broadcasting and the softmax function\n",
    "\n",
    "A very important concept to understand in numpy is \"broadcasting\". It is very useful for performing mathematical operations between arrays of different shapes. For the full details on broadcasting, you can read the official [broadcasting documentation](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task**: Implement a `softmax()` function using numpy. You can think of softmax as a normalizing function used when your algorithm needs to classify two or more classes. You will learn more about `softmax` in this course.\n",
    "\n",
    "**Instructions**:\n",
    "\n",
    "- $ \\text{for } x \\in \\mathbb{R}^{1\\times n} \\text{,     } \\text{softmax}(x) = \\text{softmax}(\\begin{bmatrix}\n",
    "    x_1  &&\n",
    "    x_2 &&\n",
    "    ...  &&\n",
    "    x_n  \n",
    "\\end{bmatrix}) = \\begin{bmatrix}\n",
    "     \\frac{e^{x_1}}{\\sum_{j}e^{x_j}}  &&\n",
    "    \\frac{e^{x_2}}{\\sum_{j}e^{x_j}}  &&\n",
    "    ...  &&\n",
    "    \\frac{e^{x_n}}{\\sum_{j}e^{x_j}} \n",
    "\\end{bmatrix} $ \n",
    "\n",
    "- $\\text{for a matrix } x \\in \\mathbb{R}^{m \\times n} \\text{,  $x_{ij}$ maps to the element in the $i^{th}$ row and $j^{th}$ column of $x$, thus we have: }$\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{softmax}(x) = \\text{softmax}\n",
    "\\begin{bmatrix}\n",
    "    x_{11} & x_{12} & x_{13} & \\dots  & x_{1n} \\\\\n",
    "    x_{21} & x_{22} & x_{23} & \\dots  & x_{2n} \\\\\n",
    "    \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "    x_{m1} & x_{m2} & x_{m3} & \\dots  & x_{mn}\n",
    "\\end{bmatrix} = \n",
    "\\begin{bmatrix}\n",
    "    \\frac{e^{x_{11}}}{\\sum_{j}e^{x_{1j}}} & \\frac{e^{x_{12}}}{\\sum_{j}e^{x_{1j}}} & \\frac{e^{x_{13}}}{\\sum_{j}e^{x_{1j}}} & \\dots  & \\frac{e^{x_{1n}}}{\\sum_{j}e^{x_{1j}}} \\\\\n",
    "    \\frac{e^{x_{21}}}{\\sum_{j}e^{x_{2j}}} & \\frac{e^{x_{22}}}{\\sum_{j}e^{x_{2j}}} & \\frac{e^{x_{23}}}{\\sum_{j}e^{x_{2j}}} & \\dots  & \\frac{e^{x_{2n}}}{\\sum_{j}e^{x_{2j}}} \\\\\n",
    "    \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "    \\frac{e^{x_{m1}}}{\\sum_{j}e^{x_{mj}}} & \\frac{e^{x_{m2}}}{\\sum_{j}e^{x_{mj}}} & \\frac{e^{x_{m3}}}{\\sum_{j}e^{x_{mj}}} & \\dots  & \\frac{e^{x_{mn}}}{\\sum_{j}e^{x_{mj}}}\n",
    "\\end{bmatrix} = \n",
    "\\begin{pmatrix}\n",
    "    \\text{softmax}\\text{(first row of x)}  \\\\\n",
    "    \\text{softmax}\\text{(second row of x)} \\\\\n",
    "    ...  \\\\\n",
    "    \\text{softmax}\\text{(last row of x)} \\\\\n",
    "\\end{pmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "In English, if you are not quite comfortable with the notation above, if there is a vector of elements you want to calculate\n",
    "the softmax for, first you need to take the exponential of all elements.  Then you should divide each element by the sum of the\n",
    "exponential values, to calculate the `softmax` function.\n",
    "\n",
    "For your `softmax()` function, you should expect a 2 dimensional array of values as input.  The `softmax()` function should\n",
    "perform the `softmax` on each row.  So you need to correctly sum each row and then divide the values of the row by\n",
    "the sum of the row.  Remember, do **NOT** use loops or iteration to do this.  You again should be able to use broadcasting\n",
    "to correctly perform the division and get the needed softmax normalization of each row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_matrix (test_assg_tasks.test_softmax.test_matrix)\n",
      "test_matrix ... FAIL\n",
      "test_random_matrix (test_assg_tasks.test_softmax.test_random_matrix)\n",
      "test_random_matrix ... FAIL\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_matrix (test_assg_tasks.test_softmax.test_matrix)\n",
      "test_matrix\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/defer.py\", line 216, in maybeDeferred\n",
      "    result = f(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 227, in runWithWarningsSuppressed\n",
      "    raise exc_info[1].with_traceback(exc_info[2])\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 223, in runWithWarningsSuppressed\n",
      "    result = f(*a, **kw)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/workspaces/assg02/src/test_assg_tasks.py\", line 229, in test_matrix\n",
      "    self.assertTrue(np.allclose(s, expected_s))\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/trial/_synctest.py\", line 402, in assertTrue\n",
      "    super().assertTrue(condition, msg)\n",
      "twisted.trial.unittest.FailTest: False is not true\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_random_matrix (test_assg_tasks.test_softmax.test_random_matrix)\n",
      "test_random_matrix\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/defer.py\", line 216, in maybeDeferred\n",
      "    result = f(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 227, in runWithWarningsSuppressed\n",
      "    raise exc_info[1].with_traceback(exc_info[2])\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 223, in runWithWarningsSuppressed\n",
      "    result = f(*a, **kw)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/workspaces/assg02/src/test_assg_tasks.py\", line 239, in test_random_matrix\n",
      "    self.assertTrue(s.shape == (20,10))\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/trial/_synctest.py\", line 402, in assertTrue\n",
      "    super().assertTrue(condition, msg)\n",
      "twisted.trial.unittest.FailTest: False is not true\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 0.007s\n",
      "\n",
      "FAILED (failures=2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "softmax(x) returned:\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "#### TESTED FUNCTION softmax()\n",
    "run_unittests(['test_softmax'])\n",
    "\n",
    "x = np.array([\n",
    "    [9, 2, 5, 0, 0],\n",
    "    [7, 5, 0, 0 ,0]])\n",
    "\n",
    "s = softmax(x)\n",
    "print('softmax(x) returned:')\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Results**: For the given input array, you should get the following output from your softmax function:\n",
    "\n",
    "```\n",
    "softmax(x) returned:\n",
    "[[9.80897665e-01 8.94462891e-04 1.79657674e-02 1.21052389e-04 1.21052389e-04]\n",
    " [8.78679856e-01 1.18916387e-01 8.01252314e-04 8.01252314e-04 8.01252314e-04]]\n",
    "```\n",
    "\n",
    "**Note**:\n",
    "\n",
    "Again you should look at the shape of your sum for the matrix `x` that has 2 rows and 5 columns, you should see that\n",
    "you summed the rows and got a shape of (2, 1).  When you divide by this sum, the sum is broadcast to the\n",
    "exponential of `x` which is also of shape (2, 5), so the sum for each row is broadcast to divide the value\n",
    "in each row.\n",
    "\n",
    "Congratulations! You now have a pretty good understanding of python numpy and have implemented a few useful functions that you will be using in machine learning.\n",
    "\n",
    "Now that the last task for part 1 is completed, make and push a commit to your GitHub Classroom repository\n",
    "and ensure all tasks completed so far are passing in the autograder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.5 Implement one-hot Encoding of Categorical Data\n",
    "\n",
    "Another common task you will need to perform is turning categorical data into a suitable numerical representation.  For example, in the\n",
    "previous example of the Iris dataset, one of the columns serves as the target label for the data.  This was the category of the\n",
    "flower for that sample of the data, one of the discrete set of 3 flowers: `[Setosa, Versicolor, Virginica]`\n",
    "\n",
    "For categorical data that will be used as a target label, one approach is to simply assign a unique integer for each of the categories.  So we might\n",
    "assign `0` for `Setosa`, `1` for `Versicolor` and `2` for `Virginica` in this case.\n",
    "\n",
    "However, if the category needs to be used as an input feature for training, a simple integer value to represent the category can be problematic, as\n",
    "we will discuss in class.  An alternative type of encoding for categorical data is known as one-hot encoding.\n",
    "\n",
    "For one hot encoding, you will be given an array of string like `object` instances.  In our Iris example, there are 3 unique values in the flower\n",
    "category.  The function you implement will return a new array with the same number of samples as your input, but with a number of feature\n",
    "columns equal to the number of unique values in the category.  For example, given an array of 5 samples, like this:\n",
    "\n",
    "```\n",
    "category = ['Setosa', 'Versicolor', 'Setosa', 'Virginica', 'Virginica']\n",
    "```\n",
    "\n",
    "The result should be a `(5, 3)` shaped on-hot encoded array.  The first column feature will encode if the category is `Setosa`, the second if it is `Versicolor` and the third\n",
    "if it is `Virginica`, like this:\n",
    "\n",
    "|     | $x_1$ | $x_2$ | $x_3$ |\n",
    "|-----|-------|-------|-------|\n",
    "| (1) |   1   |   0   |   0   |\n",
    "| (2) |   0   |   1   |   0   |\n",
    "| (3) |   1   |   0   |   0   |\n",
    "| (4) |   0   |   0   |   1   |\n",
    "| (5) |   0   |   0   |   1   |\n",
    "\n",
    "\n",
    "**Note**: It is possible to vectorize this funciton, but you should not try for a fully vectorized implementation unless looking for a challenge.  For this runction you can\n",
    "use a loop.  There are several non-vectorized approaches.  A common approach is to first determine the number of uniqe values in the input array, and use this\n",
    "with the number of input samples to create an array of all 0's with the correct number of sample rows and one-hot columns for the unique values.  Then iterate over\n",
    "each sample in the input, determine which column index needs to be set, and set that column index for the sample to 1.\n",
    "\n",
    "**Note**: You need to use `np.unique()` to determine the array of unique values.  It appears that `unique` will sort the unique values alphabetically, and this is what\n",
    "the testing of your funciton expects to be done in determine the mapping from each unique category to the column/index of its one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_bigger_case (test_assg_tasks.test_one_hot.test_bigger_case)\n",
      "test_bigger_case ... FAIL\n",
      "test_example_case (test_assg_tasks.test_one_hot.test_example_case)\n",
      "test_example_case ... FAIL\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_bigger_case (test_assg_tasks.test_one_hot.test_bigger_case)\n",
      "test_bigger_case\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/defer.py\", line 216, in maybeDeferred\n",
      "    result = f(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 227, in runWithWarningsSuppressed\n",
      "    raise exc_info[1].with_traceback(exc_info[2])\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 223, in runWithWarningsSuppressed\n",
      "    result = f(*a, **kw)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/workspaces/assg02/src/test_assg_tasks.py\", line 301, in test_bigger_case\n",
      "    self.assertTrue(one_hot_array.shape == (30, 10))\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/trial/_synctest.py\", line 402, in assertTrue\n",
      "    super().assertTrue(condition, msg)\n",
      "twisted.trial.unittest.FailTest: False is not true\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_example_case (test_assg_tasks.test_one_hot.test_example_case)\n",
      "test_example_case\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/defer.py\", line 216, in maybeDeferred\n",
      "    result = f(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 227, in runWithWarningsSuppressed\n",
      "    raise exc_info[1].with_traceback(exc_info[2])\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 223, in runWithWarningsSuppressed\n",
      "    result = f(*a, **kw)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/workspaces/assg02/src/test_assg_tasks.py\", line 259, in test_example_case\n",
      "    self.assertTrue(one_hot_array.shape == (5,3))\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/trial/_synctest.py\", line 402, in assertTrue\n",
      "    super().assertTrue(condition, msg)\n",
      "twisted.trial.unittest.FailTest: False is not true\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 0.006s\n",
      "\n",
      "FAILED (failures=2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one_hot returned:\n",
      "[0]\n",
      "(1,)\n"
     ]
    }
   ],
   "source": [
    "#### TESTED FUNCTION one_hot()\n",
    "run_unittests(['test_one_hot'])\n",
    "\n",
    "category = np.array(['Setosa', 'Versicolor', 'Setosa', 'Virginica', 'Virginica'])\n",
    "one_hot_array = one_hot(category)\n",
    "\n",
    "print('one_hot returned:')\n",
    "print(one_hot_array)\n",
    "print(one_hot_array.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected output**: For the example set of category strings, you should get the following one-hot encoded array:\n",
    "\n",
    "```\n",
    "one_hot returned:\n",
    "[[1. 0. 0.]\n",
    " [0. 1. 0.]\n",
    " [1. 0. 0.]\n",
    " [0. 0. 1.]\n",
    " [0. 0. 1.]]\n",
    "(5, 3)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>\n",
    "    \n",
    "**What you need to remember:**\n",
    "- np.exp(x) works for any np.array x and applies the exponential function to every coordinate\n",
    "- the sigmoid function and its gradient are common activation functions you will see more of in this class\n",
    "- numpy has efficient built-in functions\n",
    "- broadcasting is extremely useful\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Vectorization\n",
    "\n",
    "In machine learning, you deal with very large datasets. Hence, a non-computationally-optimal function can become a huge bottleneck in your algorithm and can result in a model that takes ages to run. To make sure that your code is  computationally efficient, you will use vectorization. For example, try to tell the difference between the following implementations of the dot/outer/elementwise product for vectore and matrix multiplications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naive_add computation time: 57.539805 ms\n",
      "\n",
      "naive_vector_dot: 261.848849\n",
      "naive_vector_dot computation time: 15.661624 ms\n",
      "\n",
      "naive_matrix_dot computation time: 1997.603257 ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "v1 = np.random.random((1000,))\n",
    "v2 =  np.random.random((1000,))\n",
    "x1 = np.random.random((50,50))\n",
    "x2 = np.random.random((50,50))\n",
    "num_trials = 100\n",
    "\n",
    "# naive element wise addition using loops\n",
    "def naive_add(x, y):\n",
    "    assert len(x.shape) == 2\n",
    "    assert x.shape == y.shape\n",
    "    x = x.copy()\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "            x[i, j] += y[i, j]\n",
    "    return x\n",
    "\n",
    "tic = time.process_time()\n",
    "for trial in range(num_trials):\n",
    "    x3 = naive_add(x1, x2)\n",
    "toc = time.process_time()\n",
    "print(\"naive_add computation time: %f ms\\n\" % (1000 * (toc - tic)))\n",
    "\n",
    "# naive vector dot product using loops\n",
    "def naive_vector_dot(x, y):\n",
    "    assert len(x.shape) == 1\n",
    "    assert len(y.shape) == 1\n",
    "    assert x.shape[0] == y.shape[0]\n",
    "    z = 0\n",
    "    for i in range(x.shape[0]):\n",
    "        z += x[i] * y[i]\n",
    "    return z\n",
    "    \n",
    "tic = time.process_time()\n",
    "for trial in range(num_trials):\n",
    "    dot = naive_vector_dot(v1, v2)\n",
    "toc = time.process_time()\n",
    "print(\"naive_vector_dot: %f\" % dot)\n",
    "print(\"naive_vector_dot computation time: %f ms\\n\" % (1000 * (toc - tic)))\n",
    "\n",
    "# naive matrix dot product (matrix multiplication\n",
    "def naive_matrix_dot(x, y):\n",
    "    assert len(x.shape) == 2\n",
    "    assert len(y.shape) == 2\n",
    "    assert x.shape[1] == y.shape[0]\n",
    "    z = np.zeros((x.shape[0], y.shape[1]))\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(y.shape[1]):\n",
    "            row_x = x[i, :]\n",
    "            column_y = y[:, j]\n",
    "            z[i, j] = naive_vector_dot(row_x, column_y)\n",
    "    return z\n",
    "\n",
    "tic = time.process_time()\n",
    "for trial in range(num_trials):\n",
    "    dot = naive_matrix_dot(x1, x2)\n",
    "toc = time.process_time()\n",
    "print(\"naive_matrix_dot computation time: %f ms\\n\" % (1000 * (toc - tic)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy vectorized add computation time: 0.388540 ms\n",
      "\n",
      "np.dot: 261.848849\n",
      "np.dot vectorized computation time on vectors: 0.646713 ms\n",
      "\n",
      "np.dot vectorized computation time on matrices: 5.245111 ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# numpy element wise add\n",
    "tic = time.process_time()\n",
    "for trials in range(num_trials):\n",
    "    x3 = x1 + x2\n",
    "toc = time.process_time()\n",
    "print(\"numpy vectorized add computation time: %f ms\\n\" % (1000 * (toc - tic)))\n",
    "\n",
    "# numpy vectoriced dot products of same vectors\n",
    "tic = time.process_time()\n",
    "for trials in range(num_trials):\n",
    "    dot = np.dot(v1, v2)\n",
    "toc = time.process_time()\n",
    "print(\"np.dot: %f\" % dot)\n",
    "print(\"np.dot vectorized computation time on vectors: %f ms\\n\" % (1000 * (toc - tic)))\n",
    "\n",
    "# numpy vectorized matrix dot product\n",
    "tic = time.process_time()\n",
    "for trials in range(num_trials):\n",
    "    x3 = np.dot(x1, x2)\n",
    "toc = time.process_time()\n",
    "print(\"np.dot vectorized computation time on matrices: %f ms\\n\" % (1000 * (toc - tic)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you may have noticed, the vectorized implementation is much cleaner and more efficient. For bigger vectors/matrices, the differences in running time become even bigger. \n",
    "\n",
    "**Note** that `np.dot()` performs a matrix-matrix or matrix-vector multiplication. This is different from `np.multiply()` and the `*` operator (which is equivalent to  `.*` in Matlab/Octave), which performs an element-wise multiplication."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.1: Implement the Mean Absolute Error (MAE) Regression Loss Function\n",
    "\n",
    "You will be introduced to two performance measures early in this class for measuring how well a ML model is performing on a regression problem.\n",
    "Let's first implement the simpler of the two, the Mean Absolute Error (MAE).  Formally we can define MAE as:\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{MAE}(X, h) = \\frac{1}{n} \\sum_{i=1}^n \\big | h(x^{(i)}) - y^{(i)} \\big |\n",
    "\\end{equation}\n",
    "\n",
    "In this expression, $X$ is a set of input data, just like we saw previously, with `n` samples and `m` features.  So $x^{(i)}$ refers to the $i^{th}$ sample of the input data $X$ here.\n",
    "$h$ is the hypothesis function, for whatever is the current machine learning model, it takes an input sample $x^{(i)}$ and returns the predicted target value or label.  So sometimes\n",
    "you might see that $\\hat{y}^{(i)} = h(x^{(i)})$ is the prediction of the current model for the $i^{th}$ sample input.  So you can think of $y^{(i)}$ as the true target value and\n",
    "$\\hat{y}^{(i)}$ as the model's prediction for the $i^{th}$ sample.  So you might also see the MAE written more simply as:\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{RMSE}(\\hat{y}, y) = \\frac{1}{n} \\sum_{i=1}^n \\big | \\hat{y}^{(i)} - y^{(i)} \\big |\n",
    "\\end{equation}\n",
    "\n",
    "**Task**: Implement the numpy vectorized version of the Mean Absolute Error and call it `mae()`. You may find the function `abs(x)` (absolute value of x) in `numpy` useful.  This function\n",
    "will take the `y_pred` predicted targets and the `y_true` true target labels as input vectors, both of shape `(n,)`.\n",
    "\n",
    "**Hint**: This function should be vectorized, so do NOT use a loop to sum up the absolute value of the differences.  You can use `np.sum()` instead for example.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_case1 (test_assg_tasks.test_mae.test_case1)\n",
      "test_case1 ... FAIL\n",
      "test_case2 (test_assg_tasks.test_mae.test_case2)\n",
      "test_case2 ... FAIL\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_case1 (test_assg_tasks.test_mae.test_case1)\n",
      "test_case1\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/defer.py\", line 216, in maybeDeferred\n",
      "    result = f(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 227, in runWithWarningsSuppressed\n",
      "    raise exc_info[1].with_traceback(exc_info[2])\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 223, in runWithWarningsSuppressed\n",
      "    result = f(*a, **kw)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/workspaces/assg02/src/test_assg_tasks.py\", line 313, in test_case1\n",
      "    self.assertAlmostEqual(loss, 0.22000000000000003)\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/trial/_synctest.py\", line 565, in assertAlmostEqual\n",
      "    raise self.failureException(\n",
      "twisted.trial.unittest.FailTest: 0.0 != 0.22000000000000003 within 7 places\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_case2 (test_assg_tasks.test_mae.test_case2)\n",
      "test_case2\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/defer.py\", line 216, in maybeDeferred\n",
      "    result = f(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 227, in runWithWarningsSuppressed\n",
      "    raise exc_info[1].with_traceback(exc_info[2])\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 223, in runWithWarningsSuppressed\n",
      "    result = f(*a, **kw)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/workspaces/assg02/src/test_assg_tasks.py\", line 319, in test_case2\n",
      "    self.assertAlmostEqual(loss, 0.35)\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/trial/_synctest.py\", line 565, in assertAlmostEqual\n",
      "    raise self.failureException(\n",
      "twisted.trial.unittest.FailTest: 0.0 != 0.35 within 7 places\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 0.004s\n",
      "\n",
      "FAILED (failures=2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae(y_pred, y_true) returned:\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "#### TESTED FUNCTION mae()\n",
    "run_unittests(['test_mae'])\n",
    "\n",
    "y_pred = np.array([0.9, 0.2, 0.1, 0.4, 0.9])\n",
    "y_true = np.array([1.0, 0.0, 0.0, 1.0, 1.0])\n",
    "loss = mae(y_pred, y_true)\n",
    "\n",
    "print('mae(y_pred, y_true) returned:')\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected output**: You should get the following loss value for MAE for the given set of predictions and true\n",
    "targets:\n",
    "\n",
    "```\n",
    "mae(y_pred, y_true) returned:\n",
    "0.22000000000000003\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.2: Implement the Root Mean Squared Error (RMSE) Regression Loss Function\n",
    "\n",
    "The Root Mean Squared Error (RMSE) is similar, but instead of using the absolute value, we square the errors.  Also since we square the errors, after summing\n",
    "all of the squared erros and taking their average, we apply the square root to bring the result back into the same range as the original units used.  So looking directly at the \n",
    "version of RMSE that takes a set of true labels, and the predictions from some model, RMSE is defined formally as:\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{RMSE}(\\hat{y}, y) = \\sqrt{\\frac{1}{n} \\sum_{i=1}^n (\\hat{y}^{(i)} - y^{(i)})^2}\n",
    "\\end{equation}\n",
    "\n",
    "**Exercise**: Implement the numpy vectorized version of Root Mean Squared Error function called `rmse()`.  This function takes two vectors of the same shape `(n,)` as input, which\n",
    "are the predicted target/label from a ML model, and the true target/label for a set of data to be evaluated.\n",
    "\n",
    "Make sure you implement your function in a vectorized way, you should not use a loop in the implementation of your `rmse()` function.  **Hint**: You could use\n",
    "`sum()` again, but also commonly the vector dot product is used to implement RMSE.  For example, the dot product of two vectors is defined \n",
    "as:\n",
    "\n",
    "\\begin{equation}\n",
    "a \\cdot b = \\sum_{i=1}^n a_1 b_1 + a_2 b_2 + \\cdots + a_n b_n\n",
    "\\end{equation}\n",
    "\n",
    "You can use the dot product to vectorize the sum of the squares by realizing that the dot product of the differences between the predictions and true values will result in the sum of\n",
    "the squared differences here.\n",
    "\n",
    "Also **Note**: The final result of this function should be the root mean of the sum of the squared differences.  So you will need to introspect to determine the number of samples\n",
    "`n` in order to calculate the mean, and you also need to apply the square root to your result before returning the final RMSE loss from your function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_case1 (test_assg_tasks.test_rmse.test_case1)\n",
      "test_case1 ... FAIL\n",
      "test_case2 (test_assg_tasks.test_rmse.test_case2)\n",
      "test_case2 ... FAIL\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_case1 (test_assg_tasks.test_rmse.test_case1)\n",
      "test_case1\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/defer.py\", line 216, in maybeDeferred\n",
      "    result = f(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 227, in runWithWarningsSuppressed\n",
      "    raise exc_info[1].with_traceback(exc_info[2])\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 223, in runWithWarningsSuppressed\n",
      "    result = f(*a, **kw)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/workspaces/assg02/src/test_assg_tasks.py\", line 331, in test_case1\n",
      "    self.assertAlmostEqual(loss, 0.29325756597230357)\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/trial/_synctest.py\", line 565, in assertAlmostEqual\n",
      "    raise self.failureException(\n",
      "twisted.trial.unittest.FailTest: 0.0 != 0.29325756597230357 within 7 places\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_case2 (test_assg_tasks.test_rmse.test_case2)\n",
      "test_case2\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/defer.py\", line 216, in maybeDeferred\n",
      "    result = f(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 227, in runWithWarningsSuppressed\n",
      "    raise exc_info[1].with_traceback(exc_info[2])\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 223, in runWithWarningsSuppressed\n",
      "    result = f(*a, **kw)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/workspaces/assg02/src/test_assg_tasks.py\", line 337, in test_case2\n",
      "    self.assertAlmostEqual(loss, 0.3807886552931954)\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/trial/_synctest.py\", line 565, in assertAlmostEqual\n",
      "    raise self.failureException(\n",
      "twisted.trial.unittest.FailTest: 0.0 != 0.3807886552931954 within 7 places\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 0.006s\n",
      "\n",
      "FAILED (failures=2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse(y_pred, y_true) returned:\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "#### TESTED FUNCTION rmse()\n",
    "run_unittests(['test_rmse'])\n",
    "\n",
    "y_pred = np.array([0.9, 0.2, 0.1, 0.4, 0.9])\n",
    "y_true = np.array([1.0, 0.0, 0.0, 1.0, 1.0])\n",
    "loss = rmse(y_pred, y_true)\n",
    "\n",
    "print('rmse(y_pred, y_true) returned:')\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Result**: For the predicted and true vectors you should get a RMSE loss of:\n",
    "\n",
    "```\n",
    "rmse(y_pred, y_true) returned:\n",
    "0.29325756597230357\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have completed the task, make sure you make a comment and push it up to your GitHub classroom\n",
    "repository.  If you have successfully completed all tasks, then you should be getting a full score\n",
    "of 100 in the autograder for this assignment.\n",
    "\n",
    "Congratulations on completing this assignment.  We hope that this assignment has helped you in getting\n",
    "started and to understand how assignment workflows work for this class.  Also the functions you wrote here\n",
    "should be a good review and/or motivation to learn some of the basic skills of using Python and Numpy that\n",
    "you will need for this course.  Most all of the functions and concepts you saw here will be used in this course, though\n",
    "you may not have seen all of them yet in your course materials."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>\n",
    "    \n",
    "**What to remember:**\n",
    "- Vectorization is very important in machine learning. It provides computational efficiency and clarity.\n",
    "- You have reviewed two common loss function for regression problems, RMSE and MAE.\n",
    "- You are familiar with many numpy functions such as `np.sum`, `np.dot`, `np.multiply`, `np.maximum`, etc..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
